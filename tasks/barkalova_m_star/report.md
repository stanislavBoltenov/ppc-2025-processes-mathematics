
- Студент: Баркалова Мария Константиновна, группа 3823Б1ПМоп3
- Технология: SEQ, MPI
- Вариант: 8


## 1. Введение
В современном мире эффективная коммуникация между процессами является критически важным аспектом. С увеличением масштабов вычислительных систем и сложности решаемых задач возрастает потребность в оптимизации межпроцессного взаимодействия. Одной из топологий коммуникации в параллельных системах является топология "Звезда", где один центральный узел координирует взаимодействие всех периферийных узлов.

## 2. Постановка задачи
Задача: реализовать топологию сети передачи данных "Звезда"

Вход: структура `StarMessage`, которая содержит:
- source — номер процесса-отправителя
- dest — номер процесса-получателя
- data — вектор целых чисел для передачи

Формат выходных данных: вектор целых чисел (полученные данные)

Ограничения:
- Запрещено использовать `MPI_Cart_Create` и `MPI_Graph_Create`

## 3. Описание базового алгоритма (последовательный)

копируем вектор из входных данных `GetInput()` и присваиваем выходным `GetOutput()`.

## 4. Схема распараллеливания 

Центр всегда rank 0, а периферийные узлы - rank от 1 до n-1

процесс передачи реализован следующим образом
варианты:
1. Отправка самому себе (source = dest):
- Данные остаются на том же процессе. Выходной вектор на процессе-отправителе копируется из входного вектора
2. Центр → Периферия (source = 0, dest ≠ 0):
- Центральный процесс (rank 0) отправляет напрямую получателю
3. Периферия → Центр (source ≠ 0, dest = 0):
- Отправитель посылает данные процессу 0
4. Периферия → Периферия (source ≠ 0, dest ≠ 0):
- Отправитель → Процесс 0 → Получатель


## 5. Детали реализации
Архитектура проекта:
- последовательная версия: barkalova_m_star/seq/
- MPI-версия: barkalova_m_star/mpi/
- общий компонент: barkalova_m_star/common/
- тесты: barkalova_m_star/tests/

Для передачи используются стандартные MPI-операции Send/Recv

## 6. Experimental Setup
- CPU: AMD Ryzen 5 3500U with Radeon Vega Mobile Gfx     2.10 GHz   (4 cores, 8 threads)
- RAM: 8 GB
- OS: Windows 10 version 22H2
- Компилятор: MinGW GCC 6.3.0

## 7. Экспериментальные результаты
### 7.1 Корректность
Корректность проверена с помощью функциональных тестов, которые описывают разные варианты передачи данных

### 7.2 Производительность

| Mode        | Count | Time, s  | Speedup | Efficiency |
|-------------|-------|----------|---------|------------|
| seq         | 1     |  0.0002  |   1.00  | N/A        |
| mpi         | 2     |  0.0024  |   0.083 | 4.17%      |
| mpi         | 4     |  0.0042  |   0.048 | 1.19%      |
| mpi         | 6     |  0.0045  |   0.044 | 0.74%      |

Мы видим такие результаты, потому что в последовательной версии данные просто копируются в памяти без межпроцессных взаимодействий, что гораздо быстрее (так как происходит передача данных без трудоемких вычислений).


## 8. Заключение
В работе была разработана и реализована топология сети передачи данных "Звезда". Разработанный алгоритм корректно выполняет маршрутизацию данных через центральный узел для разных сценариев передачи: центр - периферия, периферия - периферия и отправка самому себе.
Это демонстрирует классические преимущества звездообразной топологии.

## 9. Источники
Документация Microsoft MPI (MS-MPI).