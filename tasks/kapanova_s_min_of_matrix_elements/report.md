# Минимальное значение элементов матрицы

- Студент: Капанова Софья Максимовна, группа 3823Б1ПМоп3
- Tехнологии: SEQ | MPI
- Вариант: 14

## 1. Введение
Задача поиска минимального элемента в матрице является фундаментальной операцией в вычислительной математике и анализе данных. 

Стандартные методы обработки матриц, выполняемые последовательно на одном процессоре, не всегда демонстрируют высокую эффективность при работе с большими объемами данных. Время выполнения операций может становиться неприемлемо большим. 

Распределение вычислений между несколькими процессами может позволить достичь значительного ускорения обработки. Однако применение параллельных вычислений не всегда приводит к ожидаемому ускорению. В случае операций с низкой вычислительной сложностью накладные расходы на организацию взаимодействия между процессами могут превышать вычислительную выгоду от распараллеливания. 

Цель работы - реализовать и проанализировать эффективность MPI-реализации алгоритма поиска минимального значения элементов матрицы по сравнению с последовательной версией.

## 2. Постановка задачи
### Формальное определение: 
Для матрицы A размером M×N найти значение min(A[i][j]), где 0 ≤ i < M, 0 ≤ j < N.
(для заданной матрицы целых чисел найти минимальный элемент)

### Входные данные: 
Двумерный вектор целых чисел типа std::vector<std::vector<int>>

### Выходные данные: 
Целое число - минимальный элемент матрицы

### Ограничения:
- Все строки матрицы должны иметь одинаковую длину
- Поддерживаются значения от INT_MIN до INT_MAX включительно
- В случае с пустой матрицей возвращается значение INT_MAX

## 3. Описание базового алгоритма (последовательный)

Алгоритм реализует поэлементное сравнение всех элементов матрицы для нахождения наименьшего значения.

Создается переменная min_value, которая инициализируется максимальным значением типа int (INT_MAX).

### Последовательность выполнения:

1. Валидация входных данных (в методе ValidationImpl()): 
- Проверка, что все строки имеют одинаковую длину
- Проверка на пустую матрицу

2. Предварительная обработка (в методе PreProcessingImpl()):
Инициализация результата значением INT_MAX

3. Основные вычисления (в методе RunImpl()):

Если матрица пустая - возврат INT_MAX

Двойной цикл по всем элементам матрицы:
Для каждой строки i матрицы:
Для каждого элемента j в строке i:
Выполняется сравнение текущего элемента matrix[i][j] с min_value (для каждого элемента выполняется сравнение с текущим минимумом)
Если matrix[i][j] < min_value, то min_value = matrix[i][j] (обновление минимума)

4. Пост-обработка (в методе PostProcessingImpl()):
Финализация результатов, возвращается значение min_value

## 4. Схема распараллеливания

1. Модель распределения данных:
Исходная матрица преобразуется в линейную последовательность элементов, которая разделяется на непрерывные блоки элементов равного размера. Каждый вычислительный процесс получает для обработки определенный блок.

2. Топология: Одноранговая модель с координацией через процесс 0

3. Роли рангов: 
- Процесс 0: координация, валидация данных, распределение нагрузки
- Все процессы: обработка своих блоков данных, вычисление локальных минимумов

4. Ключевые этапы:

Валидация и инициализация входных данных (процесс 0)

Распределение вычислительной нагрузки (распределение индексов элементов между процессами)

Параллельное вычисление локальных минимумов

Используется MPI_Allreduce с операцией MPI_MIN для глобальной редукции

Получение итогового значения всеми процессами


## 5. Детали реализации 

### Архитектура проекта:

- последовательная версия: kapanova_s_min_of_matrix_elements/seq/
- MPI-версия: kapanova_s_min_of_matrix_elements/mpi/
- общий компонент: kapanova_s_min_of_matrix_elements/common/
- тесты: kapanova_s_min_of_matrix_elements/tests/

### Ключевые классы и функции: 
- класс KapanovaSMinOfMatrixElementsMPI с реализацией параллельной версии метода
- класс KapanovaSMinOfMatrixElementsSEQ с реализацией последовательной версии метода
- определение пространства имен namespace kapanova_s_min_of_matrix_elements с определеним используемых типов данных:  
    using InType = std::vector<std::vector<int>>; - тип входных данных  
    using OutType = int; - тип возвращаемых данных  
    using TestType = std::tuple<InType, OutType>;  
    using BaseTask = ppc::task::Task<InType, OutType>;  

### Особые случаи обработки матрицы

1. Пустая матрица:   
Возвращается значение INT_MAX

2. Матрица с одним элементом:   
Значение X сразу принимается как минимальное, алгоритм завершается за одну итерацию  

3. Корректно обрабатываются комбинации положительных, отрицательных чисел и нуля   

Все отрицательные: возвращается наименьшее отрицательное число  

Граничные значения: поддерживаются значения от INT_MIN до INT_MAX включительно

4. Неправильная форма матрицы:     
Проверка выполняется в методе ValidationImpl(), при обнаружении строк разной длины возвращается ошибка

5. Матрица с повторяющимися минимальными значениями:  
Возвращается значение минимального элемента независимо от его количества в матрице

6. Все элементы матрицы имеют одинаковое значение:  
Возвращается это значение как минимальное

## 6. Experimental Setup

### Аппаратное обеспечение/ОС
- OS: MacOS Tahoe 26.1: 
- Процессор: Apple M1, 
- Вычислительные ядра: 8 ядер (4 высокопроизводительных + 4 энергоэффективных)
- RAM: 8 ГБ

### Набор инструментов:
- Компилятор: Apple Clang 17.0.0 (clang-1700.4.4.1)
- Реализация MPI: Open MPI 5.0.8
- Параметры запуска: mpiexec -n <count>
- build type Release

## 7. Results and Discussion

### 7.1 Корректность
Проверка корректности осуществлялась путем сравнения результатов параллельной MPI-реализации с эталонным значением (при этом все MPI запуски должны возвращать идентичный результат), в качестве которого был принят результат работы последовательного алгоритма (SEQ версии). В свою очередь, его корректность проверена аналитически для всех граничных случаев (были разработаны тестовые случаи с известными ожидаемыми результатами)

Особые проверки: см. пункт 5

Корректность подтверждена:
- Полным совпадением результатов MPI-реализации с эталонной SEQ версией
- Идентичностью результатов при различном количестве MPI-процессов (1, 2, 4, 6, 8)
- Успешным прохождением функциональных тестов

### 7.2 Производительность

| Mode        | Count | Time, ms | Speedup | Efficiency |
|-------------|-------|----------|---------|------------|
| seq         | 1     | 3.51     | 1.00    | N/A        |
| mpi         | 2     | 15.74    | 0.22    | 11.2%      |
| mpi         | 4     | 25.82    | 0.14    | 3.4%       |
| mpi         | 6     | 60.20    | 0.06    | 1.0%       |
| mpi         | 8     | 92.49    | 0.04    | 0.5%       |

- Speedup = T_seq / T_parallel
- Efficiency = Speedup / Count × 100%

Результаты демонстрируют неэффективность использования MPI в задаче поиска минимального элемента матрицы. Накладные расходы на коммуникацию и распределение данных значительно превышают вычислительную нагрузку операции сравнения. Наилучший результат достигнут при использовании 2 процессов с эффективностью 51%, однако дальнейшее увеличение количества процессов приводит к существенному замедлению. 

## 8. Заключение

Разработаны последовательная (SEQ) и параллельная (MPI) версии алгоритма поиска минимального элемента матрицы. 
Проведенное исследование демонстрирует, что эффективность параллельных вычислений существенно зависит от характера решаемой задачи. Для операций с низкой вычислительной сложностью, таких как поиск минимума матрицы, накладные расходы MPI могут превышать преимущества распараллеливания. Полученные результаты подтверждают, что выбор технологии параллелизации должен основываться на тщательном анализе соотношения вычислительной нагрузки и коммуникационных издержек для каждой конкретной задачи.

## 9. Источники
1. Документация по курсу «Параллельное программирование» - URL: https://learning-process.github.io/parallel_programming_course/ru/