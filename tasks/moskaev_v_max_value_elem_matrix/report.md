#<Максимальное значение элементов матрицы>
Студент: Москаев Владимир Александрович, группа: 3823Б1ПМоп3

Технология: MPI, SEQ

Вариант: 13 

## 1. Введение
Задача заключается в поиске максимального элемента в матрице. Цель — реализовать параллельный алгоритм поиска максимального элемента с использованием технологии MPI и сравнить его производительность с последовательной версией.

## 2. Постановка задачи
Формальная постановка: Для заданной матрицы A размером M×N найти элемент с максимальным значением.

Входные данные: Двумерный вектор std::vector<std::vector<int>> - матрица целых чисел.

Выходные данные: Целое число - максимальный элемент матрицы.

Ограничения:
- Матрица может быть неквадратной
- Все элементы целочисленные
- Матрица может быть пустой (в этом случае результат равен 0)

## 3. Последовательный алгоритм:
Базовый алгоритм последовательно обходит все элементы матрицы:

int max_element = matrix[0][0];
for (const auto &row : matrix) {
    for (int element : row) {
        max_element = std::max(element, max_element);
    }
}
Сложность: O(M×N), где M - количество строк, N - количество столбцов.

## 4. Схема распараллеливания
MPI реализация
Декомпозиция данных: Матрица распределяется по строкам между процессами. Каждый процесс получает свой набор строк для обработки.

Распределение строк:
int rows_per_process = total_rows / size;
int remainder = total_rows % size;
int my_rows = rows_per_process + (rank < remainder ? 1 : 0);

Коммуникационная схема:
Корневой процесс (ранг 0) преобразует матрицу в одномерный массив и передаёт части данных процессам с помощью MPI_Scatterv
Каждый процесс находит локальный максимум в своей части матрицы
Используется MPI_Allreduce для нахождения глобального максимума
Все процессы получают результат одновременно

## 5. Детали реализации
Структура кода:
ops_mpi.hpp/cpp - MPI реализация
ops_seq.hpp/cpp - последовательная реализация
common.hpp - общие типы данных
main.cpp - функциональные тесты
main.cpp - производительностные тесты

Ключевые классы:

MoskaevVMaxValueElemMatrixMPI - MPI версия задачи
MoskaevVMaxValueElemMatrixSEQ - последовательная версия

## 6. Экспериментальная установка
Аппаратное обеспечение:

CPU: Intel Core i5-11400H (6 cores, 12 threads)
RAM: 16 GB
OS: Windows 10


Компилятор: GCC 15.2.0


Тестовые данные:
Для функциональных тестов: матрицы размеров 7×7, 20×20, 50×50, 100×100, 11×11, 0×0, 1×1
Для производительностных тестов: 10000×10000
Данные генерируются случайно с равномерным распределением

## 7. Результаты
### 7.1 Корректность
Корректность реализации проверяется с помощью:
Сравнения результатов MPI и последовательной версий

Все тесты проходят успешно, что подтверждает корректность реализации.

### 7.2 Производительность
Результаты для матрицы 5000×5000:


|Тест	        |Режим	  |Время (сек)	  |Ускорение        |Эффективность|
|---------------|---------|---------------|------------     |-------------|
|Pipeline Run	|MPI	  |0.2349	      |3.92× медленнее	|6.4%         |
|Task Run	    |MPI	  |0.2355	      |3.76× медленнее  |6.3%         |
|Pipeline Run	|SEQ	  |0.0600	      |1.00×	        |100%         |
|Task Run	    |SEQ	  |0.0626	      |1.04×	        |96%          |

Наблюдения:
Причины замедления MPI версии:
   - Накладные расходы на коммуникацию: операции `MPI_Bcast`, `MPI_Scatterv` и `MPI_Allreduce` требуют времени
   - Распределение данных: преобразование матрицы в одномерный массив и его распределение
   - Недостаточный объем вычислений: для операции поиска максимума (O(n)) накладные расходы MPI могут превышать выгоду от распараллеливания
   - Размер матрицы: при 10000×10000 элементов, каждый процесс обрабатывает ~25 миллионов элементов, но операция сравнения очень быстрая

   при усложнении вычислений, эффективность mpi версии выростет

## 8. Выводы
1. Корректность: обе реализации (SEQ и MPI) работают корректно и проходят все функциональные тесты
2. Производительность:
   - Последовательная версия оказывается эффективнее MPI версии для данной задачи
   - Накладные расходы на межпроцессное взаимодействие превышают выгоду от параллельных вычислений для операции поиска максимума

3. Рекомендации:
   - Для простых операций над матрицами (поиск максимума, суммы) последовательная реализация может быть предпочтительнее
   - MPI имеет смысл применять для более сложных вычислений с большим объемом обработки данных на каждом процессе
   - Для улучшения производительности MPI версии можно:Увеличить размер матрицы для лучшего соотношения вычислений/коммуникаций

4. Общий итог: Реализация демонстрирует корректную работу в многопроцессной среде, но для конкретной задачи поиска максимума в матрице последовательный алгоритм оказывается более эффективным из-за низкой вычислительной сложности операции относительно накладных расходов MPI.